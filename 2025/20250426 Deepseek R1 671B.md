個人雖然裝了 Ubuntu 一個多月，但多數也都只是用圖形介面。30 年前曾經學過很基礎的 Unix，當然都忘光了。

經過將近兩週斷續的奮鬥，我完成了以下兩種環境的服務執行及 Open WebUI 連線:
- 3070 + WSL + Podman
- 4090 + Ubuntu + Podman + Proxy

尚有待努力:
- 兩台串聯（分散式部署）上課中未完成
- 老師後續補充有關壓測 [benchmark_serving.py](https://github.com/vllm-project/vllm/blob/main/benchmarks/benchmark_serving.py)，以及我自己寫的 [llm-load-test](https://github.com/ChrisTorng/llm-load-test)
- Dockerfile 內容

保哥整理的 [企業級 LLM 叢集部署實戰工作坊 (DeepSeek R1 671B)](https://learn.duotify.com/courses/ai-deploy-labs) 非常精華。如果跟著順順做完成功，能學到的還是有限。我親自踩過其中不少坑，其中遇到的每一個問題，怎樣進行障礙排除，學到什麼知識與技巧，才是真正累積下來的資產。

其中的 Dockerfile，我只有約略瀏覽，這又是另一個極度濃縮的精華，希望後續還有時間繼續消化。

由這次的經驗，我學到還是一步步依官網文件做最可靠。將錯誤訊息貼給 ChatGPT (4o/o4-mini 等) 想得到正確解答還是有很多困難，繞了不少冤枉路。

底下列出我這次參考到的相關網頁:
- nVidia
  - [CUDA on WSL User Guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)
  - [Support for Container Device Interface](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/cdi-support.html)
- Podman
  - [GPU container access](https://podman-desktop.io/docs/podman/gpu)
  - [Accessing Podman from another WSL distribution](https://podman-desktop.io/docs/podman/accessing-podman-from-another-wsl-instance)

有些認為是保哥整理說明步驟內可以再補充或修正的，我會再寫出來。另還有更多細節，希望我還有時間，可以後續再整理出來。

---

首先是有關 保哥整理的 [企業級 LLM 叢集部署實戰工作坊 (DeepSeek R1 671B)](https://learn.duotify.com/courses/ai-deploy-labs) 文件中我認為可以改善的:

- 有關 `sudo apt-get update` 相關部份，我自己都用 `sudo apt update`。就我目前認知，`apt-get` 好像比較舊，`apt` 是新一代的指令。剛剛查到的參考文件 [Difference Between apt and apt-get Commands \[Explained\]](https://itsfoss.com/apt-vs-apt-get-difference/)。
- `mulitnode-vllm-sgl` 拼錯字，應該是 `multinode-vllm-sgl`，`it` vs `ti`。
- Jupyter 步驟寫在啟動服務之後，我誤以為是要在已啟動服務的狀態下再執行 Jupyter。還找到按 Ctrl+Z 之後再執行 `bg` 指令的方式真的可以做到。不過建議把 Jupyter 寫在啟動服務之前，並標明是選擇性步驟。這也是上課中講師為大家事前的準備，實際上是停在這步。
- Jupyter 執行中顯示出來的網址 http://127.0.0.1:8888/lab?token=61cdf263a40314364498b9006d5dd2c37aa9682170befe5d 直接就可以用來登入，應該不用特別再提取得 token，再開啟 http://127.0.0.1:8888/ 並填入 token 值這樣的步驟。
- Jupyter 裡面若要 `sudo`，密碼由 `Dockerfile` 裡面看到應該是 `SSH_PASSWORD` 的 `multinode1234567`，並非上課中用到的 `deepseek1234567`。
- 

以上跳過 WSL/Podman/Proxy 部份，另 Grows.ai 部份我還沒做過，因此無法提供意見。

---

可惜我是做到最後還是沒有成功的，也沒機會進行壓測了。
先前上課及這次針對問題的解答，我還是沒有搞懂。
也許單純只是想太多，不過更需要的是基本觀念有待再補強，我再自己另外加強。
底下提供個人的學習項目。

在課前預備中，我學習到:

我有 WSL + Podman 及 Ubuntu + Podman 兩個環境。除了將指令中所有 `docker` 改為 `podman` 之外，還有:

首先是 WSL Podman 連線問題:
[Accessing Podman from another WSL distribution](https://podman-desktop.io/docs/podman/accessing-podman-from-another-wsl-instance)
我實際上是詢問 ChatGPT 後做出來的，實際步驟可能不比以上標準文件，這裡就不列出來了。

[CUDA on WSL User Guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)
這裡說 WSL 不用安裝 nVidia 驅動，我實測執行 `nvidia-smi` 正常。

參考 [Support for Container Device Interface](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/cdi-support.html)，要將這兩行:
```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```
改為:
```bash
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml
```
確認目前的 GPU
```bash
nvidia-ctk cdi list
=> INFO[0000] Found 2 CDI devices
   nvidia.com/gpu=0
   nvidia.com/gpu=all
```

但 WSL 目前仍卡在執行標準的指令失敗:
```bash
podman run --rm --device nvidia.com/gpu=all --security-opt=label=disable ubuntu nvidia-smi -L
=> Error: preparing container a96f1e2456cd9333795c4c5f8b1b40f099eab1d159f793a31c313e49e789027b for attach: setting up CDI devices: unresolvable CDI devices nvidia.com/gpu=all
```

我的 Ubuntu 環境有成功。
---

在實戰中，我學習到:
`sudo su` 切換到超級使用者
