開源深思模型的威力

![](Images/20240908.jpg)

[Reflection-Llama-3.1-70B](https://huggingface.co/mattshumer/Reflection-Llama-3.1-70B)

> Reflection Llama-3.1 70B 是 (目前) 世界頂級的開源 LLM ，採用一種名為 Reflection-Tuning 的新技術進行訓練，該技術教會 LLM 檢測其推理中的錯誤並糾正過程。
>
> 在取樣過程中，模型將首先在 \<thinking\> 和 \</thinking\> 標籤內輸出推理，然後一旦對其推理滿意，它將在 \<output\> 和 \</output\> 標籤。每個標籤都是特殊的標記，經過訓練進入模型。
>
> 這使得模型能夠將其內部思想和推理與其最終答案分開，從而改善使用者的體驗。
>
> 在 \<thinking\> 部分中，模型可能會輸出一個或多個 \<reflection\> 標籤，這表示模型在推理中發現了錯誤，並將在提供最終答案之前嘗試修正該錯誤。

這看起來就跟我先前這篇 [Claude 的能力探究](https://christorng.substack.com/p/claude) 使用 \<antThinking\> 的方法雷同。

可惜試用網頁 [Reflection 70B Playground](https://reflection-playground-production.up.railway.app/) 目前暫時不可用。[HyperWrite debuts Reflection 70B, most powerful open source LLM](https://venturebeat.com/ai/meet-the-new-most-powerful-open-source-ai-model-in-the-world-hyperwrites-reflection-70b/) 這邊說在 60 秒後回應了正確答案。我想，任何模型的能力，都有可能以更長的反思來更加提升，當然代價就是更長的回應時間及更高的成本。

裡面還說:

> 該模型根據 [Glaive](https://glaive.ai/) 產生的合成資料進行訓練。如果您正在訓練模型，Glaive 非常棒 — 請使用它們。

這些特殊標記當然不會在任何預訓練資料中看到，這裡可看到使用合成資料的巨大好處。模型架構不用調整，參數不用增加，只要在 微調/推理 階段使用更多的反思 tokens，就可以在現有的模型中搾出更多的能力。

> 該資料集和詳細說明我們如何訓練該模型的簡要報告將於下週發布，同時我們預計將成為世界上表現最好的 LLM 的 Reflection 405B 模型 (包括閉源模型)。

已推出的 70B 就已經是頂級成果，405B 更值得期待...看哪時有繁體中文模型...