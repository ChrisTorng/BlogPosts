# o1-mini/Claude 3.5 Sonnet compare, o1 alike and the next Orion
# o1-mini/Claude 3.5 Sonnet 比較，o1 推理模仿及下一代 Orion

![](<Images/DALL·E 2024-09-17 12.26.36 - A widescreen cover image comparing OpenAI's o1-mini with Claude 3.5 Sonnet. The image should visually depict the two AI models as abstract, futuristic.webp>)

* [LiveBench](https://livebench.ai/) / [o1-preview is SOTA on the aider leaderboard](https://aider.chat/2024/09/12/o1.html)<br>
  Claude 3.5 Sonnet 至少在程式方面，並沒有明顯比 o1-preview/mini 差，在 LiveBench 中程式能力還明顯高一截。

* [I used o1-mini everyday for coding against Claude Sonnet 3.5 so you don't have to - my thoughts](https://www.reddit.com/r/ClaudeAI/comments/1fhjgcr/i_used_o1mini_everyday_for_coding_against_claude/)<br>
  受限於 o1-mini 的每週限制數量，回答速度，再加上它的 128K 輸入/64K 輸出 tokens，它不適合高頻率快速對話互動使用，而是一次性的大問題解決。若它誤解了你的完整意圖，還得要來回反覆再澄清，就浪費了大量的 時間/長度/次數。<br>
  為了一次完成大問題解決，最好要撰寫詳細提示，提供完整範例，包括邊緣狀態的提醒等。最好一次詢問，一次就完成。而後續的細部處理小問題，再切回一般的 LLM 互動式詢問小修小調等。

以下是我參考資料源的整理:

|             |  o1-mini  | Claude 3.5 Sonnet |
|-------------|:---------:|:-----------------:|
| 輸入 tokens |    128K   |      **200K**     |
| 輸出 tokens |   **64K** |          8K       |
| 速度        |     慢    |       **快**      |
| 次數限制    | 每週 30 次 |  **每五小時重設**  |
| 最後知識    | 2023/10   |    **2024/4**     |
| 公開日期    | 2024/9/12 |      2024/6/20    |

因為 ChatGPT 畫面反應很慢，我還經常遇到凍結的現象 (Claude 不會)，又因 o1 提示經常需要寫比較長，經常會有多行，要考慮比較久，因此我現在都先在記事本全部打完，再轉貼過來比較方便，不會不小心按到 Enter 送出。

o1-mini 的能力，就我目前個人的經驗，並沒有明顯超過 Claude 3.5 Sonnet。再加上我仍然覺得 ChatGPT 左側一堆歷史對話很亂，我還是喜歡 Claude 的 Projects/Artifacts。再加上 o1 速度慢，用量限制更嚴。如果二選一的話，我目前還是比較喜歡 Claude。期待 3.5 Opus 不用等太久...

其他 CoT 選項:

* [bklieger-groq/g1: g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains](https://github.com/bklieger-groq/g1)<br>
  使用 Llama 加上提示工程技巧達成類似 o1 的效果。我想當然還比不上專門訓練的 o1，不過肯定便宜得多。

* [codelion/optillm: Optimizing inference proxy for LLMs](https://github.com/codelion/optillm)<br>
  只要提供簡單的提示，這個 LLM proxy 內建多種提示優化技巧，直接提升輸出品質。其中包括類似 o1 的 CoT with Reflection: Implements chain-of-thought reasoning with \<thinking\>, \<reflection\> and \<output\> sections。裡面支援的其他方法也很值得一試究竟。

現在大家都認識並體驗了 o1 Strawberry，那傳聞中的 Orion 呢?
* [What's Ahead for OpenAI? Project Strawberry, Orion, and GPT Next - Decrypt](https://decrypt.co/247769/openai-strawberry-orion-gpt-next)
* [OpenAI's Strawberry and Orion: The Next Leap in AI Evolution](https://medium.com/@cognidownunder/openais-strawberry-and-orion-the-next-leap-in-ai-evolution-eba8d661e0a9)
* [Shaun Ralston on X: "'GPT Next' to Achieve 3 OOMs Boost.](https://x.com/shaunralston/status/1830970351825871298)
* ["ChatGPT 的活躍用戶數量為 2 億"── OpenAI 日本代表宣佈下一代模型"GPT Next" (1/2 頁)](https://www.itmedia.co.jp/aiplus/articles/2409/03/news165.html)<br>
  根據先前的傳聞，年底將推出代號為 Orion 的下一代 LLM GPT-5/GPT Next，將基於 o1 的成果，再拓展至原來的 GPT 中。實現三個數量級 (1000 倍) 算力的提升。<br>
  我推論: 利用 o1 的輸出，當作合成數據再提升 GPT Next 能力。o1 與 GPT 是不同的系列，具有不同的特性與適用場景。GPT 還有下一代，o1 同樣也會有下一代。

我的更多想法:
* Claude 是透過系統提示 (參考 [Claude 3.5 Sonnet, Full Artifacts System Prompt](https://gist.github.com/dedlim/6bf6d81f77c19e20cd40594aa09e3ecd))，讓 3.5 Sonnet 使用 \<antThinking\> XML 標籤使用深思步驟 (並且自動隱藏)。不確定為何官方公佈的 [System Prompts](https://docs.anthropic.com/en/release-notes/system-prompts#sept-9th-2024) 裡沒有。難道是只有開啟 Artifacts 才會有 \<antThinking\>???
* Claude 的方法應該是比不上預訓練即使用 CoT 文章，將完整並長時間推理的方法訓練到 LLM 大腦中。目前來說，Claude 3.5 Sonnet 的表現並明顯沒有比 o1-mini 差，我認為 Anthropic 在 CoT 方面相信早也有所推進。不知 3.5 Opus 除了參數量一定更多，是否還有什麼其他突破性的發展?
* 只利用提示工程做 CoT 已經是現在式，但各 LLM 的評測大致都是測基礎模型能力，並沒有再加各種提示工程技巧。現在 o1 內建訓練提示工程技巧來提升分數，相信其他 LLM 也會開始拿各種技巧來訓練基礎模型再追高分數。各種提示工程技巧，都可以用來從頭來做預訓練，讓提示工程技巧再也沒有存在的必要，模型本身就已經內建改善用戶提示的能力。
* 過去的 LLM，推理步驟要不了多少步，就會開始偏掉失控，無法更長時間穩定達成可靠的目標。由於 o1 公告說能力隨著推理時間而 (log 等級) 提升，未來是否有可能，可以針對真正的難題，提供用戶付費指定推理幾分鐘、幾小時、幾天的選擇???