# More o1 information
# 更多的 o1 資訊

![](<Images/DALL·E 2024-09-19 09.56.19 - A widescreen cover image for a blog post titled 'More o1 Information_ Latest Updates'. The image should emphasize advanced AI technologies, showcasing.webp>)

最新消息:

* [OpenAI on X](https://x.com/OpenAI/status/1834665203407241366)
* [OpenAI on X](https://x.com/OpenAI/status/1835857163765637607)<br>
  9/14 2:47AM (應該是台灣時間?) 為所有 Plus/Team 用戶重設了 o1-preview/mini 次數。<br>
  更新: 9/17 9:43AM 推出不到一週的時間，o1-mini 已經放寬至**每天** 50 個訊息，o1-preview 每週 **50** 個訊息!! 想要要經常使用 o1-mini 就幾乎沒負擔了，可以更多用來對話互動使用...

  **我的想法**: 這下要在 ChatGPT Plus/Claude Pro 中選一個變得更困難了...但如果 3.5 Opus 推出，應該還是可以明確勝過 o1-mini...???

* [Dyusha Gritsevskiy on X](https://x.com/dyushag/status/1834379249731444820)
* [MarcoFigueroa on X](https://x.com/MarcoFigueroa/status/1834741170024726628)<br>
  小心，企圖深入了解 o1 推理內部運作，可能會被發警告信停權!

再回頭仔細看一開始的公告:

* [Introducing OpenAI o1](https://openai.com/index/introducing-openai-o1-preview/)<br>
  未來 ChatGPT 會針對給定的提示自動選擇正確的模型。未來還會增加網頁瀏覽、檔案/圖片上傳功能。GPT 系列還會有後續版本。

  **我評論**: 對一般交談介面，自動選擇模型的功能應該有意義，API 應該不會吧?

* [OpenAI o1-mini](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)<br>
  o1-mini 在 STEM 外的知識與 GPT-4o mini 相當，未來還會再擴展到其他的領域與專業。

  **我推論**: o1-mini 的訓練資料集與 GPT-4○ mini 一樣，另外再加 STEM CoT 合成資料集。

* [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/)<br>
  > o1 在具有挑戰性的推理基準上比 GPT-4o 有了很大的改進。實心條顯示 pass@1 準確率，陰影區域顯示 64 個樣本的多數投票 (共識) 的表現。

  > o1 在每個問題只有一個樣本的情況下平均為74% (11.1/15)，在 64 個樣本之間達成一致的情況下為 83% (12.5/15)，在使用學習的評分函數對 1000 個樣本重新排序時為93% (13.9/15)。

  > 我們再訓練一個模型 (名為 o1-ioi)，從 o1 開始進行初始化，並進行訓練以進一步提高程式設計技能，它在 2024 年國際資訊學奧林匹克競賽 (IOI) 中獲得了 213 分，排名第 49 位。該模型在與人類參賽者相同的條件下參加了 2024 年 IOI 比賽。它有 10 個小時的時間來解決 6 個具有挑戰性的演算法問題，每個問題允許提交 50 份。

  > 當每個問題允許 10,000 次提交時，即使沒有任何測試時間選擇策略，該模型也能獲得 362.14 分——高於金牌門檻。

  **我推論**: pass@1 是跑一次 o1 的結果，64 樣本是跑 o1 64 次所得的結果，以多數共識決選出最佳答案。1000 樣本還另外用評分模型做出成果排序，可達更高成績。另亦未公開的 o1-ioi 模型，用十小時解六題，每題提交 50 個答案，代表平均一個答案花費兩分鐘。(不過我猜應該不是花費整整十小時，跑出整整 300 個答案吧? 300 個答案是參賽允許提交的上限，實際上沒有那麼多? 或者會提前跑完?)

  **我觀察**: 一開始顯示的 Thinking 還沒有內容，這時內部原始模型應該已經吐一堆 tokens 出來，但還在等另一個 CoT 總結模型將推理過程重點摘要 (且將機密刪除後) 顯示出來。

**我推論**: 由於 OpenAI 明確寫 CoT (Chain of Thought)，而且依據以上 64/1000/10000 樣本的說明，我認為應該不是 ToT (Tree of Thought，參考 [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/html/2305.10601))。因為若已採用 ToT，不管是深度優先或廣度優先，應該要探索過 (儘可能) 所有 (有意義之) 可能解法，照理提交多個樣本還能額外提供的改善應該很有限才對。額外提供這麼多樣本，代表問題空間足夠大，希望使用多次 CoT 亂槍打鳥方式，看能涵蓋多少可能的解法?

* [Reverse engineering OpenAI's o1](https://www.interconnects.ai/p/reverse-engineering-openai-o1)<br>
  裡面很多深入技術推測性的內容，我都看不太懂。